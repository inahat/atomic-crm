name: Scheduled DB Backup

on:
  schedule:
    - cron: '0 3 * * *' # runs daily at 03:00 UTC by default; change as needed
  workflow_dispatch: {} # allows manual run

jobs:
  backup:
    runs-on: ubuntu-latest
    env:
      BACKUP_DIR: ./backups
      RETENTION_COUNT: '14'
      S3_REGION: 'us-east-1'
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install dependencies (awscli, pg tools)
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client openssl python3 python3-pip
          pip3 install --upgrade awscli

      - name: Set environment from secrets (no-op step to document secrets)
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          PGHOST: ${{ secrets.PGHOST }}
          PGPORT: ${{ secrets.PGPORT }}
          PGUSER: ${{ secrets.PGUSER }}
          PGPASSWORD: ${{ secrets.PGPASSWORD }}
          PGDATABASE: ${{ secrets.PGDATABASE }}
          S3_ENDPOINT: ${{ secrets.S3_ENDPOINT }}
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
          S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          S3_REGION: ${{ secrets.S3_REGION }}
          BACKUP_PASSPHRASE: ${{ secrets.BACKUP_PASSPHRASE }}
        run: |
          echo "Secrets loaded into environment for subsequent steps."

      - name: Test database connection
        run: |
          echo "Testing database connectivity..."
          if [[ -n "${DATABASE_URL:-}" ]]; then
            echo "Using DATABASE_URL"
            if pg_isready -d "${DATABASE_URL}"; then
              echo "✓ Database is ready"
            else
              echo "✗ Database connection failed"
              exit 1
            fi
          else
            echo "Using individual PG credentials"
            if pg_isready -h "${PGHOST}" -p "${PGPORT}" -U "${PGUSER}" -d "${PGDATABASE}"; then
              echo "✓ Database is ready"
            else
              echo "✗ Database connection failed"
              exit 1
            fi
          fi
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          PGHOST: ${{ secrets.PGHOST }}
          PGPORT: ${{ secrets.PGPORT }}
          PGUSER: ${{ secrets.PGUSER }}
          PGPASSWORD: ${{ secrets.PGPASSWORD }}
          PGDATABASE: ${{ secrets.PGDATABASE }}

      - name: Run backup script
        run: |
          chmod +x ./scripts/backup.sh
          ./scripts/backup.sh
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          PGHOST: ${{ secrets.PGHOST }}
          PGPORT: ${{ secrets.PGPORT }}
          PGUSER: ${{ secrets.PGUSER }}
          PGPASSWORD: ${{ secrets.PGPASSWORD }}
          PGDATABASE: ${{ secrets.PGDATABASE }}
          S3_ENDPOINT: ${{ secrets.S3_ENDPOINT }}
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
          S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          S3_REGION: ${{ secrets.S3_REGION }}
          BACKUP_PASSPHRASE: ${{ secrets.BACKUP_PASSPHRASE }}
          RETENTION_COUNT: ${{ env.RETENTION_COUNT }}

      - name: Upload backup artifact
        uses: actions/upload-artifact@v4
        with:
          name: db-backup-${{ github.run_id }}-${{ github.run_number }}
          path: backups/*.enc
          retention-days: 30
